{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model based on meter_reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "import gc\n",
    "\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Needed Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get missing data\n",
    "def missing_statistics(df):    \n",
    "    statitics = pd.DataFrame(df.isnull().sum()).reset_index()\n",
    "    statitics.columns=['COLUMN NAME',\"MISSING VALUES\"]\n",
    "    statitics['TOTAL ROWS'] = df.shape[0]\n",
    "    statitics['% MISSING'] = round((statitics['MISSING VALUES']/statitics['TOTAL ROWS'])*100,2)\n",
    "    return statitics\n",
    "\n",
    "# fix missing weather data\n",
    "def fill_weather_dataset(weather_df):\n",
    "    \n",
    "    # Find Missing Dates\n",
    "    time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    start_date = datetime.datetime.strptime(weather_df['timestamp'].min(),time_format)\n",
    "    end_date = datetime.datetime.strptime(weather_df['timestamp'].max(),time_format)\n",
    "    total_hours = int(((end_date - start_date).total_seconds() + 3600) / 3600)\n",
    "    hours_list = [(end_date - datetime.timedelta(hours=x)).strftime(time_format) for x in range(total_hours)]\n",
    "\n",
    "    missing_hours = []\n",
    "    for site_id in range(16):\n",
    "        site_hours = np.array(weather_df[weather_df['site_id'] == site_id]['timestamp'])\n",
    "        new_rows = pd.DataFrame(np.setdiff1d(hours_list,site_hours),columns=['timestamp'])\n",
    "        new_rows['site_id'] = site_id\n",
    "        weather_df = pd.concat([weather_df,new_rows])\n",
    "\n",
    "        weather_df = weather_df.reset_index(drop=True)           \n",
    "\n",
    "    # Add new Features\n",
    "    weather_df[\"datetime\"] = pd.to_datetime(weather_df[\"timestamp\"])\n",
    "    weather_df[\"day\"] = weather_df[\"datetime\"].dt.day\n",
    "    weather_df[\"week\"] = weather_df[\"datetime\"].dt.week\n",
    "    weather_df[\"month\"] = weather_df[\"datetime\"].dt.month\n",
    "    \n",
    "    # Reset Index for Fast Update\n",
    "    weather_df = weather_df.set_index(['site_id','day','month'])\n",
    "\n",
    "    air_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['air_temperature'].mean(),columns=[\"air_temperature\"])\n",
    "    weather_df.update(air_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    cloud_coverage_filler = weather_df.groupby(['site_id','day','month'])['cloud_coverage'].mean()\n",
    "    # Step 2\n",
    "    cloud_coverage_filler = pd.DataFrame(cloud_coverage_filler.fillna(method='ffill'),columns=[\"cloud_coverage\"])\n",
    "\n",
    "    weather_df.update(cloud_coverage_filler,overwrite=False)\n",
    "\n",
    "    due_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['dew_temperature'].mean(),columns=[\"dew_temperature\"])\n",
    "    weather_df.update(due_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    sea_level_filler = weather_df.groupby(['site_id','day','month'])['sea_level_pressure'].mean()\n",
    "    # Step 2\n",
    "    sea_level_filler = pd.DataFrame(sea_level_filler.fillna(method='ffill'),columns=['sea_level_pressure'])\n",
    "\n",
    "    weather_df.update(sea_level_filler,overwrite=False)\n",
    "\n",
    "    wind_direction_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_direction'].mean(),columns=['wind_direction'])\n",
    "    weather_df.update(wind_direction_filler,overwrite=False)\n",
    "\n",
    "    wind_speed_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_speed'].mean(),columns=['wind_speed'])\n",
    "    weather_df.update(wind_speed_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    precip_depth_filler = weather_df.groupby(['site_id','day','month'])['precip_depth_1_hr'].mean()\n",
    "    # Step 2\n",
    "    precip_depth_filler = pd.DataFrame(precip_depth_filler.fillna(method='ffill'),columns=['precip_depth_1_hr'])\n",
    "\n",
    "    weather_df.update(precip_depth_filler,overwrite=False)\n",
    "\n",
    "    weather_df = weather_df.reset_index()\n",
    "    weather_df = weather_df.drop(['datetime','day','week','month'],axis=1)\n",
    "        \n",
    "    return weather_df\n",
    "\n",
    "# reduce memory\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = PATH = './data/'\n",
    "\n",
    "train_df = pd.read_csv(PATH + 'train.csv')\n",
    "\n",
    "building_df = pd.read_csv(PATH + 'building_metadata.csv')\n",
    "\n",
    "weather_df = pd.read_csv(PATH + 'weather_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:24: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fix weather data\n",
    "weather_df = fill_weather_dataset(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier removal\n",
    "train_df = train_df [ train_df['building_id'] != 1099 ]\n",
    "train_df = train_df.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reduce Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 757.31 MB\n",
      "Memory usage after optimization is: 322.24 MB\n",
      "Decreased by 57.4%\n",
      "Memory usage of dataframe is 0.07 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by 73.8%\n",
      "Memory usage of dataframe is 9.65 MB\n",
      "Memory usage after optimization is: 2.66 MB\n",
      "Decreased by 72.5%\n"
     ]
    }
   ],
   "source": [
    "train_df = reduce_mem_usage(train_df,use_float16=True)\n",
    "building_df = reduce_mem_usage(building_df,use_float16=True)\n",
    "weather_df = reduce_mem_usage(weather_df,use_float16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join data\n",
    "train_df = train_df.merge(building_df, left_on='building_id',right_on='building_id',how='left')\n",
    "train_df = train_df.merge(weather_df,how='left',left_on=['site_id','timestamp'],right_on=['site_id','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>23.303600</td>\n",
       "      <td>1</td>\n",
       "      <td>Education</td>\n",
       "      <td>50623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.374600</td>\n",
       "      <td>1</td>\n",
       "      <td>Education</td>\n",
       "      <td>5374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Education</td>\n",
       "      <td>5374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>175.184006</td>\n",
       "      <td>1</td>\n",
       "      <td>Education</td>\n",
       "      <td>97532</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>91.265297</td>\n",
       "      <td>1</td>\n",
       "      <td>Education</td>\n",
       "      <td>81580</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.099609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  meter            timestamp  meter_reading  site_id  \\\n",
       "0          105      0  2016-01-01 00:00:00      23.303600        1   \n",
       "1          106      0  2016-01-01 00:00:00       0.374600        1   \n",
       "2          106      3  2016-01-01 00:00:00       0.000000        1   \n",
       "3          107      0  2016-01-01 00:00:00     175.184006        1   \n",
       "4          108      0  2016-01-01 00:00:00      91.265297        1   \n",
       "\n",
       "  primary_use  square_feet  year_built  floor_count  air_temperature  \\\n",
       "0   Education        50623         NaN          5.0         3.800781   \n",
       "1   Education         5374         NaN          4.0         3.800781   \n",
       "2   Education         5374         NaN          4.0         3.800781   \n",
       "3   Education        97532      2005.0         10.0         3.800781   \n",
       "4   Education        81580      1913.0          5.0         3.800781   \n",
       "\n",
       "   cloud_coverage  dew_temperature  precip_depth_1_hr  sea_level_pressure  \\\n",
       "0             0.0         2.400391                0.0              1021.0   \n",
       "1             0.0         2.400391                0.0              1021.0   \n",
       "2             0.0         2.400391                0.0              1021.0   \n",
       "3             0.0         2.400391                0.0              1021.0   \n",
       "4             0.0         2.400391                0.0              1021.0   \n",
       "\n",
       "   wind_direction  wind_speed  \n",
       "0           240.0    3.099609  \n",
       "1           240.0    3.099609  \n",
       "2           240.0    3.099609  \n",
       "3           240.0    3.099609  \n",
       "4           240.0    3.099609  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holiday calendar import --> some kernels say that all buildings are located in the US\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "\n",
    "# feature function\n",
    "def select_features(df_given, drop_cols, build_lags_for, window=3):\n",
    "    # copy data\n",
    "    df = df_given.copy()\n",
    "    # Sort by timestamp\n",
    "    df.sort_values(\"timestamp\")\n",
    "    # reset index\n",
    "    df.reset_index(drop=True)\n",
    "    \n",
    "    # seperate the timestamp into individual features\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"],format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    df['hour'] = np.uint8(df['timestamp'].dt.hour)\n",
    "    df['day'] = np.uint8(df['timestamp'].dt.day)\n",
    "    df['weekday'] = np.uint8(df['timestamp'].dt.weekday)\n",
    "    df['month'] = np.uint8(df['timestamp'].dt.month)\n",
    "    \n",
    "    df['square_feet'] =  np.log1p(df['square_feet'])\n",
    "    \n",
    "    # build in holiday feature\n",
    "    min_date = pd.to_datetime(df[\"timestamp\"].iloc[0],format=\"%Y-%m-%d\")\n",
    "    max_date = pd.to_datetime(df[\"timestamp\"].iloc[-1],format=\"%Y-%m-%d\")\n",
    "    \n",
    "    date_range = pd.date_range(start=min_date, end=max_date)\n",
    "    us_holidays = calendar().holidays(start=date_range.min(), end=date_range.max())\n",
    "    \n",
    "    df['is_holiday'] = (df['timestamp'].dt.date.astype('datetime64').isin(us_holidays)).astype(np.int8)\n",
    "    \n",
    "    # build weekend classification (weekday starts at 0)\n",
    "    df['is_weekend'] = np.where( (df[\"weekday\"] == 5) | (df[\"weekday\"] == 6), 1, 0 )\n",
    "    \n",
    "    # build lags\n",
    "    if build_lags_for:\n",
    "        rolled = df[build_lags_for].rolling(window=window, min_periods=0)\n",
    "        lag_mean = rolled.mean().reset_index().astype(np.float16)\n",
    "        lag_std = rolled.std().reset_index().astype(np.float16)\n",
    "        \n",
    "        for col in build_lags_for:\n",
    "            df[f'{col}_mean_lag{window}'] = lag_mean[col]\n",
    "        \n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "    \n",
    "    # transform the primary usage to a number\n",
    "    le = LabelEncoder()\n",
    "    df[\"primary_use\"] = le.fit_transform(df[\"primary_use\"])\n",
    "    \n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model build\n",
    "def build_model(t, f, categorical, params, splits):\n",
    "    # measure time\n",
    "    total_start = dt.now()\n",
    "    \n",
    "    # t = target\n",
    "    # f = features\n",
    "    # categorical = categorical features of the dataset\n",
    "    # params = model parameters --> used to change to find best fit\n",
    "    # splits = kfolf number of splits\n",
    "    \n",
    "    kf = KFold(n_splits=splits)\n",
    "    # collect models\n",
    "    models = []\n",
    "    \n",
    "    for train_index,test_index in kf.split(f):\n",
    "        model_start = dt.now()\n",
    "        # train\n",
    "        train_features = f.loc[train_index]\n",
    "        train_target = t.loc[train_index]\n",
    "        \n",
    "        # test\n",
    "        test_features = f.loc[test_index]\n",
    "        test_target = t.loc[test_index]\n",
    "        \n",
    "        d_train = lgb.Dataset(train_features, label=train_target, categorical_feature=categorical, free_raw_data=False)\n",
    "        d_test = lgb.Dataset(test_features, label=test_target,categorical_feature=categorical, free_raw_data=False)\n",
    "        # explanation:\n",
    "        '''\n",
    "            label: (list, numpy 1-D array, pandas Series / one-column DataFrame or None, optional (default=None)) – Label of the data.\n",
    "            loading numpy array in the datasettt\n",
    "            free_raw_data: saves memory if set to true --> i´m not concerned on my pc\n",
    "            details:\n",
    "            https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.Dataset.html\n",
    "        '''\n",
    "        model = lgb.train(\n",
    "             params, \n",
    "             train_set=d_train, \n",
    "             num_boost_round=1000, \n",
    "             valid_sets=[d_train,d_test], \n",
    "             verbose_eval=25, \n",
    "             early_stopping_rounds=50\n",
    "        )\n",
    "        # append model to list\n",
    "        models.append(model)\n",
    "        del train_features, train_target, test_features, test_target, d_train, d_test\n",
    "        gc.collect()\n",
    "        \n",
    "        model_end = dt.now()\n",
    "        print('KFold time:', model_end - model_start)\n",
    "        \n",
    "    total_end = dt.now()\n",
    "    print('Total time:', total_end - total_start)\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build features\n",
    "train_df_features = select_features(\n",
    "    train_df,\n",
    "    [\"timestamp\",\"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"year_built\",\"floor_count\",\n",
    "     'precip_depth_1_hr', 'is_weekend', 'cloud_coverage', 'weekday'],\n",
    "    False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>23.303600</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.832181</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0.374600</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.589514</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.589514</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>175.184006</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.487946</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>91.265297</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.309352</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  meter  meter_reading  site_id  primary_use  square_feet  \\\n",
       "0          105      0      23.303600        1            0    10.832181   \n",
       "1          106      0       0.374600        1            0     8.589514   \n",
       "2          106      3       0.000000        1            0     8.589514   \n",
       "3          107      0     175.184006        1            0    11.487946   \n",
       "4          108      0      91.265297        1            0    11.309352   \n",
       "\n",
       "   air_temperature  dew_temperature  hour  day  month  is_holiday  \n",
       "0         3.800781         2.400391     0    1      1           1  \n",
       "1         3.800781         2.400391     0    1      1           1  \n",
       "2         3.800781         2.400391     0    1      1           1  \n",
       "3         3.800781         2.400391     0    1      1           1  \n",
       "4         3.800781         2.400391     0    1      1           1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate data into meter types\n",
    "train_df_features_0 = train_df_features[ (train_df_features['meter'] == 0) ]\n",
    "train_df_features_1 = train_df_features[ (train_df_features['meter'] == 1) ]\n",
    "train_df_features_2 = train_df_features[ (train_df_features['meter'] == 2) ]\n",
    "train_df_features_3 = train_df_features[ (train_df_features['meter'] == 3) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "categorical_features = [\n",
    "    \"building_id\", \"site_id\", 'primary_use', 'hour', 'day', 'month', 'meter','is_holiday'\n",
    "]\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"num_leaves\": 70,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.85,\n",
    "    \"reg_lambda\": 2,\n",
    "    \"metric\": \"rmse\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:19: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:23: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:24: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.774465\tvalid_1's rmse: 0.796547\n",
      "[50]\ttraining's rmse: 0.437352\tvalid_1's rmse: 0.513269\n",
      "[75]\ttraining's rmse: 0.361814\tvalid_1's rmse: 0.480464\n",
      "[100]\ttraining's rmse: 0.32707\tvalid_1's rmse: 0.475139\n",
      "[125]\ttraining's rmse: 0.30493\tvalid_1's rmse: 0.472645\n",
      "[150]\ttraining's rmse: 0.290375\tvalid_1's rmse: 0.472929\n",
      "[175]\ttraining's rmse: 0.278727\tvalid_1's rmse: 0.473615\n",
      "Early stopping, best iteration is:\n",
      "[128]\ttraining's rmse: 0.303427\tvalid_1's rmse: 0.472555\n",
      "KFold time: 0:00:57.623770\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.789774\tvalid_1's rmse: 0.749478\n",
      "[50]\ttraining's rmse: 0.459188\tvalid_1's rmse: 0.436302\n",
      "[75]\ttraining's rmse: 0.382549\tvalid_1's rmse: 0.396007\n",
      "[100]\ttraining's rmse: 0.345054\tvalid_1's rmse: 0.391902\n",
      "[125]\ttraining's rmse: 0.320411\tvalid_1's rmse: 0.389116\n",
      "[150]\ttraining's rmse: 0.303798\tvalid_1's rmse: 0.388411\n",
      "[175]\ttraining's rmse: 0.291483\tvalid_1's rmse: 0.387554\n",
      "[200]\ttraining's rmse: 0.282502\tvalid_1's rmse: 0.386995\n",
      "[225]\ttraining's rmse: 0.275832\tvalid_1's rmse: 0.386298\n",
      "[250]\ttraining's rmse: 0.269682\tvalid_1's rmse: 0.386255\n",
      "[275]\ttraining's rmse: 0.264469\tvalid_1's rmse: 0.38655\n",
      "Early stopping, best iteration is:\n",
      "[248]\ttraining's rmse: 0.270316\tvalid_1's rmse: 0.38606\n",
      "KFold time: 0:01:16.922513\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.747697\tvalid_1's rmse: 0.901061\n",
      "[50]\ttraining's rmse: 0.409964\tvalid_1's rmse: 0.645837\n",
      "[75]\ttraining's rmse: 0.338902\tvalid_1's rmse: 0.607843\n",
      "[100]\ttraining's rmse: 0.308945\tvalid_1's rmse: 0.60117\n",
      "[125]\ttraining's rmse: 0.288489\tvalid_1's rmse: 0.595553\n",
      "[150]\ttraining's rmse: 0.276167\tvalid_1's rmse: 0.593545\n",
      "[175]\ttraining's rmse: 0.268296\tvalid_1's rmse: 0.591665\n",
      "[200]\ttraining's rmse: 0.262029\tvalid_1's rmse: 0.590909\n",
      "[225]\ttraining's rmse: 0.257043\tvalid_1's rmse: 0.591582\n",
      "Early stopping, best iteration is:\n",
      "[190]\ttraining's rmse: 0.263913\tvalid_1's rmse: 0.590379\n",
      "KFold time: 0:01:06.788354\n",
      "Total time: 0:03:21.591074\n"
     ]
    }
   ],
   "source": [
    "# model meter = 0\n",
    "target_0 = np.log1p(train_df_features_0[\"meter_reading\"])\n",
    "features_0 = train_df_features_0.drop('meter_reading', axis = 1)\n",
    "\n",
    "test_0 = build_model(target_0, features_0, categorical_features, params, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:19: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:23: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:24: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.655676\tvalid_1's rmse: 0.607735\n",
      "[50]\ttraining's rmse: 0.409242\tvalid_1's rmse: 0.515308\n",
      "[75]\ttraining's rmse: 0.347318\tvalid_1's rmse: 0.509879\n",
      "[100]\ttraining's rmse: 0.323444\tvalid_1's rmse: 0.508482\n",
      "[125]\ttraining's rmse: 0.307851\tvalid_1's rmse: 0.508375\n",
      "[150]\ttraining's rmse: 0.29746\tvalid_1's rmse: 0.508265\n",
      "Early stopping, best iteration is:\n",
      "[106]\ttraining's rmse: 0.319243\tvalid_1's rmse: 0.507956\n",
      "KFold time: 0:00:16.789942\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.646679\tvalid_1's rmse: 0.632934\n",
      "[50]\ttraining's rmse: 0.417553\tvalid_1's rmse: 0.470837\n",
      "[75]\ttraining's rmse: 0.361799\tvalid_1's rmse: 0.449158\n",
      "[100]\ttraining's rmse: 0.338581\tvalid_1's rmse: 0.444437\n",
      "[125]\ttraining's rmse: 0.322761\tvalid_1's rmse: 0.441989\n",
      "[150]\ttraining's rmse: 0.311782\tvalid_1's rmse: 0.440381\n",
      "[175]\ttraining's rmse: 0.301519\tvalid_1's rmse: 0.438865\n",
      "[200]\ttraining's rmse: 0.29392\tvalid_1's rmse: 0.438534\n",
      "[225]\ttraining's rmse: 0.288042\tvalid_1's rmse: 0.438729\n",
      "[250]\ttraining's rmse: 0.282792\tvalid_1's rmse: 0.438451\n",
      "Early stopping, best iteration is:\n",
      "[221]\ttraining's rmse: 0.289113\tvalid_1's rmse: 0.438393\n",
      "KFold time: 0:00:23.739529\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.604222\tvalid_1's rmse: 1.04857\n",
      "[50]\ttraining's rmse: 0.392035\tvalid_1's rmse: 0.889756\n",
      "[75]\ttraining's rmse: 0.336322\tvalid_1's rmse: 0.85725\n",
      "[100]\ttraining's rmse: 0.311225\tvalid_1's rmse: 0.84201\n",
      "[125]\ttraining's rmse: 0.294225\tvalid_1's rmse: 0.836997\n",
      "[150]\ttraining's rmse: 0.283236\tvalid_1's rmse: 0.834858\n",
      "[175]\ttraining's rmse: 0.274417\tvalid_1's rmse: 0.832799\n",
      "[200]\ttraining's rmse: 0.26796\tvalid_1's rmse: 0.831978\n",
      "[225]\ttraining's rmse: 0.262639\tvalid_1's rmse: 0.831623\n",
      "[250]\ttraining's rmse: 0.257704\tvalid_1's rmse: 0.831629\n",
      "[275]\ttraining's rmse: 0.252911\tvalid_1's rmse: 0.831961\n",
      "Early stopping, best iteration is:\n",
      "[239]\ttraining's rmse: 0.260019\tvalid_1's rmse: 0.831469\n",
      "KFold time: 0:00:23.177359\n",
      "Total time: 0:01:03.793351\n"
     ]
    }
   ],
   "source": [
    "# model meter = 1\n",
    "target_1 = np.log1p(train_df_features_1[\"meter_reading\"])\n",
    "features_1 = train_df_features_1.drop('meter_reading', axis = 1)\n",
    "\n",
    "test_1 = build_model(target_1, features_1, categorical_features, params, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:19: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:23: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:24: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.703757\tvalid_1's rmse: 0.788235\n",
      "[50]\ttraining's rmse: 0.344217\tvalid_1's rmse: 0.479491\n",
      "[75]\ttraining's rmse: 0.273145\tvalid_1's rmse: 0.442246\n",
      "[100]\ttraining's rmse: 0.251825\tvalid_1's rmse: 0.437213\n",
      "[125]\ttraining's rmse: 0.23807\tvalid_1's rmse: 0.436948\n",
      "[150]\ttraining's rmse: 0.227956\tvalid_1's rmse: 0.434573\n",
      "[175]\ttraining's rmse: 0.222068\tvalid_1's rmse: 0.433653\n",
      "[200]\ttraining's rmse: 0.217391\tvalid_1's rmse: 0.433152\n",
      "[225]\ttraining's rmse: 0.213292\tvalid_1's rmse: 0.432893\n",
      "[250]\ttraining's rmse: 0.209685\tvalid_1's rmse: 0.432756\n",
      "[275]\ttraining's rmse: 0.206174\tvalid_1's rmse: 0.432638\n",
      "[300]\ttraining's rmse: 0.203205\tvalid_1's rmse: 0.432352\n",
      "[325]\ttraining's rmse: 0.200295\tvalid_1's rmse: 0.432229\n",
      "[350]\ttraining's rmse: 0.197876\tvalid_1's rmse: 0.432144\n",
      "[375]\ttraining's rmse: 0.19582\tvalid_1's rmse: 0.4321\n",
      "[400]\ttraining's rmse: 0.193744\tvalid_1's rmse: 0.431889\n",
      "[425]\ttraining's rmse: 0.191521\tvalid_1's rmse: 0.4317\n",
      "[450]\ttraining's rmse: 0.18959\tvalid_1's rmse: 0.431586\n",
      "[475]\ttraining's rmse: 0.187767\tvalid_1's rmse: 0.431758\n",
      "Early stopping, best iteration is:\n",
      "[444]\ttraining's rmse: 0.19005\tvalid_1's rmse: 0.431547\n",
      "KFold time: 0:00:24.451925\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.699811\tvalid_1's rmse: 0.775546\n",
      "[50]\ttraining's rmse: 0.329323\tvalid_1's rmse: 0.514237\n",
      "[75]\ttraining's rmse: 0.256452\tvalid_1's rmse: 0.490579\n",
      "[100]\ttraining's rmse: 0.237563\tvalid_1's rmse: 0.48868\n",
      "[125]\ttraining's rmse: 0.225948\tvalid_1's rmse: 0.489166\n",
      "Early stopping, best iteration is:\n",
      "[96]\ttraining's rmse: 0.239752\tvalid_1's rmse: 0.488439\n",
      "KFold time: 0:00:09.907322\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.722653\tvalid_1's rmse: 0.773476\n",
      "[50]\ttraining's rmse: 0.351849\tvalid_1's rmse: 0.521738\n",
      "[75]\ttraining's rmse: 0.275105\tvalid_1's rmse: 0.503607\n",
      "[100]\ttraining's rmse: 0.251462\tvalid_1's rmse: 0.501985\n",
      "[125]\ttraining's rmse: 0.237339\tvalid_1's rmse: 0.500461\n",
      "[150]\ttraining's rmse: 0.228778\tvalid_1's rmse: 0.500308\n",
      "[175]\ttraining's rmse: 0.221762\tvalid_1's rmse: 0.500194\n",
      "[200]\ttraining's rmse: 0.216859\tvalid_1's rmse: 0.499981\n",
      "[225]\ttraining's rmse: 0.21216\tvalid_1's rmse: 0.499434\n",
      "[250]\ttraining's rmse: 0.208133\tvalid_1's rmse: 0.49877\n",
      "[275]\ttraining's rmse: 0.204402\tvalid_1's rmse: 0.498622\n",
      "[300]\ttraining's rmse: 0.201907\tvalid_1's rmse: 0.498135\n",
      "[325]\ttraining's rmse: 0.199068\tvalid_1's rmse: 0.497931\n",
      "[350]\ttraining's rmse: 0.195916\tvalid_1's rmse: 0.498257\n",
      "Early stopping, best iteration is:\n",
      "[312]\ttraining's rmse: 0.200726\tvalid_1's rmse: 0.497779\n",
      "KFold time: 0:00:18.638442\n",
      "Total time: 0:00:53.061977\n"
     ]
    }
   ],
   "source": [
    "# model meter = 2\n",
    "target_2 = np.log1p(train_df_features_2[\"meter_reading\"])\n",
    "features_2 = train_df_features_2.drop('meter_reading', axis = 1)\n",
    "\n",
    "test_2 = build_model(target_2, features_2, categorical_features, params, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:19: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:23: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:24: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.438294\tvalid_1's rmse: 0.43614\n",
      "[50]\ttraining's rmse: 0.248263\tvalid_1's rmse: 0.291504\n",
      "[75]\ttraining's rmse: 0.208918\tvalid_1's rmse: 0.278918\n",
      "[100]\ttraining's rmse: 0.193178\tvalid_1's rmse: 0.278378\n",
      "[125]\ttraining's rmse: 0.182221\tvalid_1's rmse: 0.278574\n",
      "[150]\ttraining's rmse: 0.175375\tvalid_1's rmse: 0.278243\n",
      "[175]\ttraining's rmse: 0.169775\tvalid_1's rmse: 0.278188\n",
      "[200]\ttraining's rmse: 0.165154\tvalid_1's rmse: 0.278507\n",
      "Early stopping, best iteration is:\n",
      "[161]\ttraining's rmse: 0.172386\tvalid_1's rmse: 0.27813\n",
      "KFold time: 0:00:04.990121\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.437489\tvalid_1's rmse: 0.44987\n",
      "[50]\ttraining's rmse: 0.249931\tvalid_1's rmse: 0.284946\n",
      "[75]\ttraining's rmse: 0.212139\tvalid_1's rmse: 0.263482\n",
      "[100]\ttraining's rmse: 0.197353\tvalid_1's rmse: 0.259568\n",
      "[125]\ttraining's rmse: 0.187636\tvalid_1's rmse: 0.257743\n",
      "[150]\ttraining's rmse: 0.180167\tvalid_1's rmse: 0.256566\n",
      "[175]\ttraining's rmse: 0.174391\tvalid_1's rmse: 0.256008\n",
      "[200]\ttraining's rmse: 0.169616\tvalid_1's rmse: 0.255861\n",
      "[225]\ttraining's rmse: 0.165252\tvalid_1's rmse: 0.255954\n",
      "[250]\ttraining's rmse: 0.161361\tvalid_1's rmse: 0.255887\n",
      "[275]\ttraining's rmse: 0.15817\tvalid_1's rmse: 0.255737\n",
      "[300]\ttraining's rmse: 0.155542\tvalid_1's rmse: 0.255875\n",
      "Early stopping, best iteration is:\n",
      "[262]\ttraining's rmse: 0.159692\tvalid_1's rmse: 0.255692\n",
      "KFold time: 0:00:06.280383\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.422233\tvalid_1's rmse: 0.487471\n",
      "[50]\ttraining's rmse: 0.234426\tvalid_1's rmse: 0.346312\n",
      "[75]\ttraining's rmse: 0.199641\tvalid_1's rmse: 0.332498\n",
      "[100]\ttraining's rmse: 0.187206\tvalid_1's rmse: 0.331755\n",
      "[125]\ttraining's rmse: 0.178561\tvalid_1's rmse: 0.331448\n",
      "[150]\ttraining's rmse: 0.172551\tvalid_1's rmse: 0.331358\n",
      "[175]\ttraining's rmse: 0.16744\tvalid_1's rmse: 0.331761\n",
      "Early stopping, best iteration is:\n",
      "[129]\ttraining's rmse: 0.177442\tvalid_1's rmse: 0.331333\n",
      "KFold time: 0:00:04.080301\n",
      "Total time: 0:00:15.381025\n"
     ]
    }
   ],
   "source": [
    "# model meter = 3\n",
    "target_3 = np.log1p(train_df_features_3[\"meter_reading\"])\n",
    "features_3 = train_df_features_3.drop('meter_reading', axis = 1)\n",
    "\n",
    "test_3 = build_model(target_3, features_3, categorical_features, params, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OK, this looks better\n",
    "# Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/core/frame.py:4097: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 755.49 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 307.67 MB\n",
      "Decreased by 59.3%\n",
      "Memory usage of dataframe is 266.26 MB\n",
      "Memory usage after optimization is: 108.93 MB\n",
      "Decreased by 59.1%\n",
      "Memory usage of dataframe is 173.23 MB\n",
      "Memory usage after optimization is: 71.13 MB\n",
      "Decreased by 58.9%\n",
      "Memory usage of dataframe is 77.53 MB\n",
      "Memory usage after optimization is: 32.25 MB\n",
      "Decreased by 58.4%\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(PATH + 'test.csv')\n",
    "\n",
    "# split data\n",
    "test_df_0 = test_df[ (test_df['meter'] == 0) ]\n",
    "test_df_0_row_ids = test_df_0['row_id']\n",
    "test_df_0.drop(\"row_id\", axis=1, inplace=True)\n",
    "\n",
    "test_df_1 = test_df[ (test_df['meter'] == 1) ]\n",
    "test_df_1_row_ids = test_df_1['row_id']\n",
    "test_df_1.drop(\"row_id\", axis=1, inplace=True)\n",
    "\n",
    "test_df_2 = test_df[ (test_df['meter'] == 2) ]\n",
    "test_df_2_row_ids = test_df_2['row_id']\n",
    "test_df_2.drop(\"row_id\", axis=1, inplace=True)\n",
    "\n",
    "test_df_3 = test_df[ (test_df['meter'] == 3) ]\n",
    "test_df_3_row_ids = test_df_3['row_id']\n",
    "test_df_3.drop(\"row_id\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "test_df_0 = reduce_mem_usage(test_df_0)\n",
    "test_df_1 = reduce_mem_usage(test_df_1)\n",
    "test_df_2 = reduce_mem_usage(test_df_2)\n",
    "test_df_3 = reduce_mem_usage(test_df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data\n",
    "test_df_0 = test_df_0.merge(building_df,left_on='building_id',right_on='building_id',how='left')\n",
    "test_df_1 = test_df_1.merge(building_df,left_on='building_id',right_on='building_id',how='left')\n",
    "test_df_2 = test_df_2.merge(building_df,left_on='building_id',right_on='building_id',how='left')\n",
    "test_df_3 = test_df_3.merge(building_df,left_on='building_id',right_on='building_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:24: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 19.25 MB\n",
      "Memory usage after optimization is: 9.05 MB\n",
      "Decreased by 53.0%\n"
     ]
    }
   ],
   "source": [
    "# get test weather and fill it\n",
    "weather_df = pd.read_csv(PATH + 'weather_test.csv')\n",
    "\n",
    "weather_df = fill_weather_dataset(weather_df)\n",
    "\n",
    "weather_df = reduce_mem_usage(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with weather\n",
    "test_df_0 = test_df_0.merge(weather_df,how='left',on=['timestamp','site_id'])\n",
    "test_df_1 = test_df_1.merge(weather_df,how='left',on=['timestamp','site_id'])\n",
    "test_df_2 = test_df_2.merge(weather_df,how='left',on=['timestamp','site_id'])\n",
    "test_df_3 = test_df_3.merge(weather_df,how='left',on=['timestamp','site_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build features\n",
    "test_df_0_features = select_features(\n",
    "    test_df_0,\n",
    "    [\"timestamp\",\"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"year_built\",\"floor_count\",\n",
    "     'precip_depth_1_hr', 'is_weekend', 'cloud_coverage', 'weekday'],\n",
    "    False\n",
    ")\n",
    "\n",
    "test_df_1_features = select_features(\n",
    "    test_df_1,\n",
    "    [\"timestamp\",\"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"year_built\",\"floor_count\",\n",
    "     'precip_depth_1_hr', 'is_weekend', 'cloud_coverage', 'weekday'],\n",
    "    False\n",
    ")\n",
    "\n",
    "test_df_2_features = select_features(\n",
    "    test_df_2,\n",
    "    [\"timestamp\",\"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"year_built\",\"floor_count\",\n",
    "     'precip_depth_1_hr', 'is_weekend', 'cloud_coverage', 'weekday'],\n",
    "    False\n",
    ")\n",
    "\n",
    "test_df_3_features = select_features(\n",
    "    test_df_3,\n",
    "    [\"timestamp\",\"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"year_built\",\"floor_count\",\n",
    "     'precip_depth_1_hr', 'is_weekend', 'cloud_coverage', 'weekday'],\n",
    "    False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for each meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Time: 0:02:59.425484\n"
     ]
    }
   ],
   "source": [
    "prediction_start = dt.now()\n",
    "\n",
    "results_0 = []\n",
    "for model in test_0:\n",
    "    if  results_0 == []:\n",
    "        results_0 = np.expm1(model.predict(test_df_0_features, num_iteration=model.best_iteration)) / len(test_0)\n",
    "    else:\n",
    "        results_0 += np.expm1(model.predict(test_df_0_features, num_iteration=model.best_iteration)) / len(test_0)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    \n",
    "print('Prediction Time:', dt.now() - prediction_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Time: 0:00:54.007087\n"
     ]
    }
   ],
   "source": [
    "prediction_start = dt.now()\n",
    "\n",
    "results_1 = []\n",
    "for model in test_1:\n",
    "    if  results_1 == []:\n",
    "        results_1 = np.expm1(model.predict(test_df_1_features, num_iteration=model.best_iteration)) / len(test_1)\n",
    "    else:\n",
    "        results_1 += np.expm1(model.predict(test_df_1_features, num_iteration=model.best_iteration)) / len(test_1)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    \n",
    "print('Prediction Time:', dt.now() - prediction_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Time: 0:00:44.699859\n"
     ]
    }
   ],
   "source": [
    "prediction_start = dt.now()\n",
    "\n",
    "results_2 = []\n",
    "for model in test_2:\n",
    "    if  results_2 == []:\n",
    "        results_2 = np.expm1(model.predict(test_df_2_features, num_iteration=model.best_iteration)) / len(test_2)\n",
    "    else:\n",
    "        results_2 += np.expm1(model.predict(test_df_2_features, num_iteration=model.best_iteration)) / len(test_2)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    \n",
    "print('Prediction Time:', dt.now() - prediction_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Time: 0:00:13.699037\n"
     ]
    }
   ],
   "source": [
    "prediction_start = dt.now()\n",
    "\n",
    "results_3 = []\n",
    "for model in test_3:\n",
    "    if  results_3 == []:\n",
    "        results_3 = np.expm1(model.predict(test_df_3_features, num_iteration=model.best_iteration)) / len(test_3)\n",
    "    else:\n",
    "        results_3 += np.expm1(model.predict(test_df_3_features, num_iteration=model.best_iteration)) / len(test_3)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    \n",
    "print('Prediction Time:', dt.now() - prediction_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create result dataframes\n",
    "results_df_0 = pd.DataFrame({\"row_id\": test_df_0_row_ids, \"meter_reading\": np.clip(results_0, 0, a_max=None)})\n",
    "results_df_1 = pd.DataFrame({\"row_id\": test_df_1_row_ids, \"meter_reading\": np.clip(results_1, 0, a_max=None)})\n",
    "results_df_2 = pd.DataFrame({\"row_id\": test_df_2_row_ids, \"meter_reading\": np.clip(results_2, 0, a_max=None)})\n",
    "results_df_3 = pd.DataFrame({\"row_id\": test_df_3_row_ids, \"meter_reading\": np.clip(results_3, 0, a_max=None)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat(\n",
    "    [results_df_0, results_df_1, results_df_2, results_df_3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.sort_values(by=['row_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [row_id, meter_reading]\n",
       "Index: []"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicates\n",
    "t = results_df[results_df['row_id'].duplicated()]\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"submission_03.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
