{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Version of Model 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "import gc\n",
    "\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Needed functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get missing data\n",
    "def missing_statistics(df):    \n",
    "    statitics = pd.DataFrame(df.isnull().sum()).reset_index()\n",
    "    statitics.columns=['COLUMN NAME',\"MISSING VALUES\"]\n",
    "    statitics['TOTAL ROWS'] = df.shape[0]\n",
    "    statitics['% MISSING'] = round((statitics['MISSING VALUES']/statitics['TOTAL ROWS'])*100,2)\n",
    "    return statitics\n",
    "\n",
    "# fix missing weather data\n",
    "def fill_weather_dataset(weather_df):\n",
    "    \n",
    "    # Find Missing Dates\n",
    "    time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    start_date = datetime.datetime.strptime(weather_df['timestamp'].min(),time_format)\n",
    "    end_date = datetime.datetime.strptime(weather_df['timestamp'].max(),time_format)\n",
    "    total_hours = int(((end_date - start_date).total_seconds() + 3600) / 3600)\n",
    "    hours_list = [(end_date - datetime.timedelta(hours=x)).strftime(time_format) for x in range(total_hours)]\n",
    "\n",
    "    missing_hours = []\n",
    "    for site_id in range(16):\n",
    "        site_hours = np.array(weather_df[weather_df['site_id'] == site_id]['timestamp'])\n",
    "        new_rows = pd.DataFrame(np.setdiff1d(hours_list,site_hours),columns=['timestamp'])\n",
    "        new_rows['site_id'] = site_id\n",
    "        weather_df = pd.concat([weather_df,new_rows])\n",
    "\n",
    "        weather_df = weather_df.reset_index(drop=True)           \n",
    "\n",
    "    # Add new Features\n",
    "    weather_df[\"datetime\"] = pd.to_datetime(weather_df[\"timestamp\"])\n",
    "    weather_df[\"day\"] = weather_df[\"datetime\"].dt.day\n",
    "    weather_df[\"week\"] = weather_df[\"datetime\"].dt.week\n",
    "    weather_df[\"month\"] = weather_df[\"datetime\"].dt.month\n",
    "    \n",
    "    # Reset Index for Fast Update\n",
    "    weather_df = weather_df.set_index(['site_id','day','month'])\n",
    "\n",
    "    air_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['air_temperature'].mean(),columns=[\"air_temperature\"])\n",
    "    weather_df.update(air_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    cloud_coverage_filler = weather_df.groupby(['site_id','day','month'])['cloud_coverage'].mean()\n",
    "    # Step 2\n",
    "    cloud_coverage_filler = pd.DataFrame(cloud_coverage_filler.fillna(method='ffill'),columns=[\"cloud_coverage\"])\n",
    "\n",
    "    weather_df.update(cloud_coverage_filler,overwrite=False)\n",
    "\n",
    "    due_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['dew_temperature'].mean(),columns=[\"dew_temperature\"])\n",
    "    weather_df.update(due_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    sea_level_filler = weather_df.groupby(['site_id','day','month'])['sea_level_pressure'].mean()\n",
    "    # Step 2\n",
    "    sea_level_filler = pd.DataFrame(sea_level_filler.fillna(method='ffill'),columns=['sea_level_pressure'])\n",
    "\n",
    "    weather_df.update(sea_level_filler,overwrite=False)\n",
    "\n",
    "    wind_direction_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_direction'].mean(),columns=['wind_direction'])\n",
    "    weather_df.update(wind_direction_filler,overwrite=False)\n",
    "\n",
    "    wind_speed_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_speed'].mean(),columns=['wind_speed'])\n",
    "    weather_df.update(wind_speed_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    precip_depth_filler = weather_df.groupby(['site_id','day','month'])['precip_depth_1_hr'].mean()\n",
    "    # Step 2\n",
    "    precip_depth_filler = pd.DataFrame(precip_depth_filler.fillna(method='ffill'),columns=['precip_depth_1_hr'])\n",
    "\n",
    "    weather_df.update(precip_depth_filler,overwrite=False)\n",
    "\n",
    "    weather_df = weather_df.reset_index()\n",
    "    weather_df = weather_df.drop(['datetime','day','week','month'],axis=1)\n",
    "        \n",
    "    return weather_df\n",
    "\n",
    "# reduce memory\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = PATH = './data/'\n",
    "\n",
    "train_df = pd.read_csv(PATH + 'train.csv')\n",
    "\n",
    "building_df = pd.read_csv(PATH + 'building_metadata.csv')\n",
    "\n",
    "weather_df = pd.read_csv(PATH + 'weather_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:24: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fix weather data\n",
    "weather_df = fill_weather_dataset(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier removal\n",
    "# According to discussions on kaggle: \n",
    "    # https://www.kaggle.com/c/ashrae-energy-prediction/discussion/120694#latest-690700\n",
    "    # https://www.kaggle.com/c/ashrae-energy-prediction/discussion/114830#latest-680086\n",
    "\n",
    "train_df = train_df [ train_df['building_id'] != 1099 ]\n",
    "train_df = train_df.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 757.31 MB\n",
      "Memory usage after optimization is: 322.24 MB\n",
      "Decreased by 57.4%\n",
      "Memory usage of dataframe is 0.07 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by 73.8%\n",
      "Memory usage of dataframe is 9.65 MB\n",
      "Memory usage after optimization is: 2.66 MB\n",
      "Decreased by 72.5%\n"
     ]
    }
   ],
   "source": [
    "train_df = reduce_mem_usage(train_df,use_float16=True)\n",
    "building_df = reduce_mem_usage(building_df,use_float16=True)\n",
    "weather_df = reduce_mem_usage(weather_df,use_float16=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(building_df, left_on='building_id',right_on='building_id',how='left')\n",
    "train_df = train_df.merge(weather_df,how='left',left_on=['site_id','timestamp'],right_on=['site_id','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>23.303600</td>\n",
       "      <td>1</td>\n",
       "      <td>Education</td>\n",
       "      <td>50623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.374600</td>\n",
       "      <td>1</td>\n",
       "      <td>Education</td>\n",
       "      <td>5374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Education</td>\n",
       "      <td>5374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>175.184006</td>\n",
       "      <td>1</td>\n",
       "      <td>Education</td>\n",
       "      <td>97532</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>91.265297</td>\n",
       "      <td>1</td>\n",
       "      <td>Education</td>\n",
       "      <td>81580</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.099609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  meter            timestamp  meter_reading  site_id  \\\n",
       "0          105      0  2016-01-01 00:00:00      23.303600        1   \n",
       "1          106      0  2016-01-01 00:00:00       0.374600        1   \n",
       "2          106      3  2016-01-01 00:00:00       0.000000        1   \n",
       "3          107      0  2016-01-01 00:00:00     175.184006        1   \n",
       "4          108      0  2016-01-01 00:00:00      91.265297        1   \n",
       "\n",
       "  primary_use  square_feet  year_built  floor_count  air_temperature  \\\n",
       "0   Education        50623         NaN          5.0         3.800781   \n",
       "1   Education         5374         NaN          4.0         3.800781   \n",
       "2   Education         5374         NaN          4.0         3.800781   \n",
       "3   Education        97532      2005.0         10.0         3.800781   \n",
       "4   Education        81580      1913.0          5.0         3.800781   \n",
       "\n",
       "   cloud_coverage  dew_temperature  precip_depth_1_hr  sea_level_pressure  \\\n",
       "0             0.0         2.400391                0.0              1021.0   \n",
       "1             0.0         2.400391                0.0              1021.0   \n",
       "2             0.0         2.400391                0.0              1021.0   \n",
       "3             0.0         2.400391                0.0              1021.0   \n",
       "4             0.0         2.400391                0.0              1021.0   \n",
       "\n",
       "   wind_direction  wind_speed  \n",
       "0           240.0    3.099609  \n",
       "1           240.0    3.099609  \n",
       "2           240.0    3.099609  \n",
       "3           240.0    3.099609  \n",
       "4           240.0    3.099609  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLUMN NAME</th>\n",
       "      <th>MISSING VALUES</th>\n",
       "      <th>TOTAL ROWS</th>\n",
       "      <th>% MISSING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>building_id</td>\n",
       "      <td>0</td>\n",
       "      <td>19852422</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meter</td>\n",
       "      <td>0</td>\n",
       "      <td>19852422</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>timestamp</td>\n",
       "      <td>0</td>\n",
       "      <td>19852422</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meter_reading</td>\n",
       "      <td>0</td>\n",
       "      <td>19852422</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>site_id</td>\n",
       "      <td>0</td>\n",
       "      <td>19852422</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>primary_use</td>\n",
       "      <td>0</td>\n",
       "      <td>19852422</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>square_feet</td>\n",
       "      <td>0</td>\n",
       "      <td>19852422</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>year_built</td>\n",
       "      <td>12110079</td>\n",
       "      <td>19852422</td>\n",
       "      <td>61.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>floor_count</td>\n",
       "      <td>16345489</td>\n",
       "      <td>19852422</td>\n",
       "      <td>82.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>air_temperature</td>\n",
       "      <td>0</td>\n",
       "      <td>19852422</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cloud_coverage</td>\n",
       "      <td>0</td>\n",
       "      <td>19852422</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dew_temperature</td>\n",
       "      <td>0</td>\n",
       "      <td>19852422</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>precip_depth_1_hr</td>\n",
       "      <td>0</td>\n",
       "      <td>19852422</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sea_level_pressure</td>\n",
       "      <td>0</td>\n",
       "      <td>19852422</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wind_direction</td>\n",
       "      <td>0</td>\n",
       "      <td>19852422</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wind_speed</td>\n",
       "      <td>0</td>\n",
       "      <td>19852422</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           COLUMN NAME  MISSING VALUES  TOTAL ROWS  % MISSING\n",
       "0          building_id               0    19852422       0.00\n",
       "1                meter               0    19852422       0.00\n",
       "2            timestamp               0    19852422       0.00\n",
       "3        meter_reading               0    19852422       0.00\n",
       "4              site_id               0    19852422       0.00\n",
       "5          primary_use               0    19852422       0.00\n",
       "6          square_feet               0    19852422       0.00\n",
       "7           year_built        12110079    19852422      61.00\n",
       "8          floor_count        16345489    19852422      82.33\n",
       "9      air_temperature               0    19852422       0.00\n",
       "10      cloud_coverage               0    19852422       0.00\n",
       "11     dew_temperature               0    19852422       0.00\n",
       "12   precip_depth_1_hr               0    19852422       0.00\n",
       "13  sea_level_pressure               0    19852422       0.00\n",
       "14      wind_direction               0    19852422       0.00\n",
       "15          wind_speed               0    19852422       0.00"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing points\n",
    "missing_statistics(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holiday calendar import --> some kernels say that all buildings are located in the US\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "\n",
    "# feature function\n",
    "def select_features(df_given, drop_cols, build_lags_for, window=3):\n",
    "    # copy data\n",
    "    df = df_given.copy()\n",
    "    # Sort by timestamp\n",
    "    df.sort_values(\"timestamp\")\n",
    "    # reset index\n",
    "    df.reset_index(drop=True)\n",
    "    \n",
    "    # seperate the timestamp into individual features\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"],format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    df['hour'] = np.uint8(df['timestamp'].dt.hour)\n",
    "    df['day'] = np.uint8(df['timestamp'].dt.day)\n",
    "    df['weekday'] = np.uint8(df['timestamp'].dt.weekday)\n",
    "    df['month'] = np.uint8(df['timestamp'].dt.month)\n",
    "    \n",
    "    df['square_feet'] =  np.log1p(df['square_feet'])\n",
    "    \n",
    "    # build in holiday feature\n",
    "    min_date = pd.to_datetime(df[\"timestamp\"].iloc[0],format=\"%Y-%m-%d\")\n",
    "    max_date = pd.to_datetime(df[\"timestamp\"].iloc[-1],format=\"%Y-%m-%d\")\n",
    "    \n",
    "    date_range = pd.date_range(start=min_date, end=max_date)\n",
    "    us_holidays = calendar().holidays(start=date_range.min(), end=date_range.max())\n",
    "    \n",
    "    df['is_holiday'] = (df['timestamp'].dt.date.astype('datetime64').isin(us_holidays)).astype(np.int8)\n",
    "    \n",
    "    # build weekend classification (weekday starts at 0)\n",
    "    df['is_weekend'] = np.where( (df[\"weekday\"] == 5) | (df[\"weekday\"] == 6), 1, 0 )\n",
    "    \n",
    "    # build lags\n",
    "    if build_lags_for:\n",
    "        rolled = df[build_lags_for].rolling(window=window, min_periods=0)\n",
    "        lag_mean = rolled.mean().reset_index().astype(np.float16)\n",
    "        lag_std = rolled.std().reset_index().astype(np.float16)\n",
    "        \n",
    "        for col in build_lags_for:\n",
    "            df[f'{col}_mean_lag{window}'] = lag_mean[col]\n",
    "        \n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "    \n",
    "    # transform the primary usage to a number\n",
    "    le = LabelEncoder()\n",
    "    df[\"primary_use\"] = le.fit_transform(df[\"primary_use\"])\n",
    "    \n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model build\n",
    "def build_model(t, f, categorical, params, splits):\n",
    "    # measure time\n",
    "    total_start = dt.now()\n",
    "    \n",
    "    # t = target\n",
    "    # f = features\n",
    "    # categorical = categorical features of the dataset\n",
    "    # params = model parameters --> used to change to find best fit\n",
    "    # splits = kfolf number of splits\n",
    "    \n",
    "    kf = KFold(n_splits=splits)\n",
    "    # collect models\n",
    "    models = []\n",
    "    \n",
    "    for train_index,test_index in kf.split(f):\n",
    "        model_start = dt.now()\n",
    "        # train\n",
    "        train_features = f.loc[train_index]\n",
    "        train_target = t.loc[train_index]\n",
    "        \n",
    "        # test\n",
    "        test_features = f.loc[test_index]\n",
    "        test_target = t.loc[test_index]\n",
    "        \n",
    "        d_train = lgb.Dataset(train_features, label=train_target, categorical_feature=categorical, free_raw_data=False)\n",
    "        d_test = lgb.Dataset(test_features, label=test_target,categorical_feature=categorical, free_raw_data=False)\n",
    "        # explanation:\n",
    "        '''\n",
    "            label: (list, numpy 1-D array, pandas Series / one-column DataFrame or None, optional (default=None)) – Label of the data.\n",
    "            loading numpy array in the datasettt\n",
    "            free_raw_data: saves memory if set to true --> i´m not concerned on my pc\n",
    "            details:\n",
    "            https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.Dataset.html\n",
    "        '''\n",
    "        model = lgb.train(\n",
    "             params, \n",
    "             train_set=d_train, \n",
    "             num_boost_round=1000, \n",
    "             valid_sets=[d_train,d_test], \n",
    "             verbose_eval=25, \n",
    "             early_stopping_rounds=50\n",
    "        )\n",
    "        # append model to list\n",
    "        models.append(model)\n",
    "        del train_features, train_target, test_features, test_target, d_train, d_test\n",
    "        gc.collect()\n",
    "        \n",
    "        model_end = dt.now()\n",
    "        print('KFold time:', model_end - model_start)\n",
    "        \n",
    "    total_end = dt.now()\n",
    "    print('Total time:', total_end - total_start)\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build features\n",
    "train_df_features = select_features(\n",
    "    train_df,\n",
    "    [\"timestamp\",\"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"year_built\",\"floor_count\"],\n",
    "    ['air_temperature', 'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr'],\n",
    "    window=144\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model\n",
    "### target and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.68444\tvalid_1's rmse: 1.76672\n",
      "[50]\ttraining's rmse: 1.45953\tvalid_1's rmse: 1.59498\n",
      "[75]\ttraining's rmse: 1.31769\tvalid_1's rmse: 1.49426\n",
      "[100]\ttraining's rmse: 1.21632\tvalid_1's rmse: 1.43138\n",
      "[125]\ttraining's rmse: 1.14918\tvalid_1's rmse: 1.38583\n",
      "[150]\ttraining's rmse: 1.08635\tvalid_1's rmse: 1.33285\n",
      "[175]\ttraining's rmse: 1.03782\tvalid_1's rmse: 1.29074\n",
      "[200]\ttraining's rmse: 0.994779\tvalid_1's rmse: 1.25602\n",
      "[225]\ttraining's rmse: 0.965931\tvalid_1's rmse: 1.23536\n",
      "[250]\ttraining's rmse: 0.939448\tvalid_1's rmse: 1.21859\n",
      "[275]\ttraining's rmse: 0.918088\tvalid_1's rmse: 1.20503\n",
      "[300]\ttraining's rmse: 0.899126\tvalid_1's rmse: 1.19105\n",
      "[325]\ttraining's rmse: 0.881824\tvalid_1's rmse: 1.17604\n",
      "[350]\ttraining's rmse: 0.867045\tvalid_1's rmse: 1.16302\n",
      "[375]\ttraining's rmse: 0.853111\tvalid_1's rmse: 1.15258\n",
      "[400]\ttraining's rmse: 0.839511\tvalid_1's rmse: 1.14715\n",
      "[425]\ttraining's rmse: 0.829652\tvalid_1's rmse: 1.14312\n",
      "[450]\ttraining's rmse: 0.821692\tvalid_1's rmse: 1.13838\n",
      "[475]\ttraining's rmse: 0.814301\tvalid_1's rmse: 1.13254\n",
      "[500]\ttraining's rmse: 0.807783\tvalid_1's rmse: 1.12926\n",
      "[525]\ttraining's rmse: 0.8015\tvalid_1's rmse: 1.12477\n",
      "[550]\ttraining's rmse: 0.797097\tvalid_1's rmse: 1.12256\n",
      "[575]\ttraining's rmse: 0.79297\tvalid_1's rmse: 1.1215\n",
      "[600]\ttraining's rmse: 0.788892\tvalid_1's rmse: 1.12\n",
      "[625]\ttraining's rmse: 0.784901\tvalid_1's rmse: 1.11903\n",
      "[650]\ttraining's rmse: 0.781581\tvalid_1's rmse: 1.11707\n",
      "[675]\ttraining's rmse: 0.778137\tvalid_1's rmse: 1.11664\n",
      "[700]\ttraining's rmse: 0.775013\tvalid_1's rmse: 1.11582\n",
      "[725]\ttraining's rmse: 0.771752\tvalid_1's rmse: 1.11526\n",
      "[750]\ttraining's rmse: 0.768553\tvalid_1's rmse: 1.11332\n",
      "[775]\ttraining's rmse: 0.765378\tvalid_1's rmse: 1.11282\n",
      "[800]\ttraining's rmse: 0.763048\tvalid_1's rmse: 1.11147\n",
      "[825]\ttraining's rmse: 0.760905\tvalid_1's rmse: 1.11015\n",
      "[850]\ttraining's rmse: 0.758123\tvalid_1's rmse: 1.10968\n",
      "[875]\ttraining's rmse: 0.755321\tvalid_1's rmse: 1.10843\n",
      "[900]\ttraining's rmse: 0.753135\tvalid_1's rmse: 1.10796\n",
      "[925]\ttraining's rmse: 0.75123\tvalid_1's rmse: 1.10744\n",
      "[950]\ttraining's rmse: 0.749462\tvalid_1's rmse: 1.10679\n",
      "[975]\ttraining's rmse: 0.747347\tvalid_1's rmse: 1.10634\n",
      "[1000]\ttraining's rmse: 0.745783\tvalid_1's rmse: 1.10614\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.745783\tvalid_1's rmse: 1.10614\n",
      "KFold time: 0:07:13.452543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:23: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:24: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.64757\tvalid_1's rmse: 1.70593\n",
      "[50]\ttraining's rmse: 1.38602\tvalid_1's rmse: 1.5137\n",
      "[75]\ttraining's rmse: 1.23122\tvalid_1's rmse: 1.39752\n",
      "[100]\ttraining's rmse: 1.13876\tvalid_1's rmse: 1.3199\n",
      "[125]\ttraining's rmse: 1.08234\tvalid_1's rmse: 1.27112\n",
      "[150]\ttraining's rmse: 1.03451\tvalid_1's rmse: 1.22618\n",
      "[175]\ttraining's rmse: 0.999655\tvalid_1's rmse: 1.19268\n",
      "[200]\ttraining's rmse: 0.971949\tvalid_1's rmse: 1.17083\n",
      "[225]\ttraining's rmse: 0.945152\tvalid_1's rmse: 1.154\n",
      "[250]\ttraining's rmse: 0.917801\tvalid_1's rmse: 1.13435\n",
      "[275]\ttraining's rmse: 0.899701\tvalid_1's rmse: 1.12235\n",
      "[300]\ttraining's rmse: 0.883021\tvalid_1's rmse: 1.11178\n",
      "[325]\ttraining's rmse: 0.867833\tvalid_1's rmse: 1.10156\n",
      "[350]\ttraining's rmse: 0.854879\tvalid_1's rmse: 1.08906\n",
      "[375]\ttraining's rmse: 0.844124\tvalid_1's rmse: 1.08016\n",
      "[400]\ttraining's rmse: 0.835075\tvalid_1's rmse: 1.0742\n",
      "[425]\ttraining's rmse: 0.827775\tvalid_1's rmse: 1.06777\n",
      "[450]\ttraining's rmse: 0.822203\tvalid_1's rmse: 1.06317\n",
      "[475]\ttraining's rmse: 0.815543\tvalid_1's rmse: 1.0606\n",
      "[500]\ttraining's rmse: 0.809381\tvalid_1's rmse: 1.05774\n",
      "[525]\ttraining's rmse: 0.802595\tvalid_1's rmse: 1.05453\n",
      "[550]\ttraining's rmse: 0.796382\tvalid_1's rmse: 1.05265\n",
      "[575]\ttraining's rmse: 0.792324\tvalid_1's rmse: 1.0502\n",
      "[600]\ttraining's rmse: 0.788316\tvalid_1's rmse: 1.04828\n",
      "[625]\ttraining's rmse: 0.784163\tvalid_1's rmse: 1.04764\n",
      "[650]\ttraining's rmse: 0.78092\tvalid_1's rmse: 1.04589\n",
      "[675]\ttraining's rmse: 0.776869\tvalid_1's rmse: 1.04474\n",
      "[700]\ttraining's rmse: 0.773459\tvalid_1's rmse: 1.04314\n",
      "[725]\ttraining's rmse: 0.770606\tvalid_1's rmse: 1.04179\n",
      "[750]\ttraining's rmse: 0.767808\tvalid_1's rmse: 1.03944\n",
      "[775]\ttraining's rmse: 0.76533\tvalid_1's rmse: 1.03792\n",
      "[800]\ttraining's rmse: 0.762602\tvalid_1's rmse: 1.03603\n",
      "[825]\ttraining's rmse: 0.760129\tvalid_1's rmse: 1.03526\n",
      "[850]\ttraining's rmse: 0.758438\tvalid_1's rmse: 1.0349\n",
      "[875]\ttraining's rmse: 0.756434\tvalid_1's rmse: 1.03399\n",
      "[900]\ttraining's rmse: 0.754012\tvalid_1's rmse: 1.0332\n",
      "[925]\ttraining's rmse: 0.751658\tvalid_1's rmse: 1.03208\n",
      "[950]\ttraining's rmse: 0.749055\tvalid_1's rmse: 1.03176\n",
      "[975]\ttraining's rmse: 0.747349\tvalid_1's rmse: 1.0311\n",
      "[1000]\ttraining's rmse: 0.745319\tvalid_1's rmse: 1.03065\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.745319\tvalid_1's rmse: 1.03065\n",
      "KFold time: 0:06:48.247360\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.69552\tvalid_1's rmse: 1.73073\n",
      "[50]\ttraining's rmse: 1.46579\tvalid_1's rmse: 1.52606\n",
      "[75]\ttraining's rmse: 1.32727\tvalid_1's rmse: 1.41393\n",
      "[100]\ttraining's rmse: 1.21608\tvalid_1's rmse: 1.33526\n",
      "[125]\ttraining's rmse: 1.13632\tvalid_1's rmse: 1.28103\n",
      "[150]\ttraining's rmse: 1.06184\tvalid_1's rmse: 1.23722\n",
      "[175]\ttraining's rmse: 1.00563\tvalid_1's rmse: 1.20658\n",
      "[200]\ttraining's rmse: 0.966736\tvalid_1's rmse: 1.18797\n",
      "[225]\ttraining's rmse: 0.935319\tvalid_1's rmse: 1.17467\n",
      "[250]\ttraining's rmse: 0.906134\tvalid_1's rmse: 1.16136\n",
      "[275]\ttraining's rmse: 0.885256\tvalid_1's rmse: 1.15303\n",
      "[300]\ttraining's rmse: 0.867078\tvalid_1's rmse: 1.14499\n",
      "[325]\ttraining's rmse: 0.853255\tvalid_1's rmse: 1.14012\n",
      "[350]\ttraining's rmse: 0.839581\tvalid_1's rmse: 1.1352\n",
      "[375]\ttraining's rmse: 0.829911\tvalid_1's rmse: 1.13227\n",
      "[400]\ttraining's rmse: 0.82062\tvalid_1's rmse: 1.12682\n",
      "[425]\ttraining's rmse: 0.812039\tvalid_1's rmse: 1.12372\n",
      "[450]\ttraining's rmse: 0.805525\tvalid_1's rmse: 1.11926\n",
      "[475]\ttraining's rmse: 0.799984\tvalid_1's rmse: 1.11679\n",
      "[500]\ttraining's rmse: 0.795168\tvalid_1's rmse: 1.11411\n",
      "[525]\ttraining's rmse: 0.790872\tvalid_1's rmse: 1.11222\n",
      "[550]\ttraining's rmse: 0.786507\tvalid_1's rmse: 1.11134\n",
      "[575]\ttraining's rmse: 0.782861\tvalid_1's rmse: 1.11028\n",
      "[600]\ttraining's rmse: 0.779434\tvalid_1's rmse: 1.10873\n",
      "[625]\ttraining's rmse: 0.775851\tvalid_1's rmse: 1.10786\n",
      "[650]\ttraining's rmse: 0.771428\tvalid_1's rmse: 1.10731\n",
      "[675]\ttraining's rmse: 0.768518\tvalid_1's rmse: 1.10677\n",
      "[700]\ttraining's rmse: 0.765961\tvalid_1's rmse: 1.10603\n",
      "[725]\ttraining's rmse: 0.763399\tvalid_1's rmse: 1.10603\n",
      "[750]\ttraining's rmse: 0.760754\tvalid_1's rmse: 1.10616\n",
      "[775]\ttraining's rmse: 0.758229\tvalid_1's rmse: 1.10599\n",
      "Early stopping, best iteration is:\n",
      "[731]\ttraining's rmse: 0.762956\tvalid_1's rmse: 1.1059\n",
      "KFold time: 0:05:23.828129\n",
      "Total time: 0:19:26.121366\n"
     ]
    }
   ],
   "source": [
    "# Test 1:\n",
    "target = np.log1p(train_df_features[\"meter_reading\"])\n",
    "features = train_df_features.drop('meter_reading', axis = 1)\n",
    "\n",
    "categorical_features = [\n",
    "    \"building_id\", \"site_id\", 'primary_use', \n",
    "    'hour', 'weekday', 'meter',\n",
    "    'is_holiday', 'is_weekend'\n",
    "]\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"num_leaves\": 70,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"feature_fraction\": 0.85,\n",
    "    \"reg_lambda\": 2,\n",
    "    \"metric\": \"rmse\",\n",
    "}\n",
    "\n",
    "test_1 = build_model(target, features, categorical_features, params, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ok, we see some improvement across the folds\n",
    "### seems like a little overfitting with too much params\n",
    "# Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 954.38 MB\n",
      "Memory usage after optimization is: 199.59 MB\n",
      "Decreased by 79.1%\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(PATH + 'test.csv')\n",
    "\n",
    "row_ids = test_df[\"row_id\"]\n",
    "\n",
    "test_df.drop(\"row_id\", axis=1, inplace=True)\n",
    "\n",
    "test_df = reduce_mem_usage(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data\n",
    "test_df = test_df.merge(building_df,left_on='building_id',right_on='building_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:24: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 19.25 MB\n",
      "Memory usage after optimization is: 9.05 MB\n",
      "Decreased by 53.0%\n"
     ]
    }
   ],
   "source": [
    "# get test weather and fill it\n",
    "weather_df = pd.read_csv(PATH + 'weather_test.csv')\n",
    "\n",
    "weather_df = fill_weather_dataset(weather_df)\n",
    "\n",
    "weather_df = reduce_mem_usage(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.merge(weather_df,how='left',on=['timestamp','site_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build features\n",
    "test_df_features = select_features(\n",
    "    test_df,\n",
    "    [\"timestamp\",\"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"year_built\",\"floor_count\"],\n",
    "    ['air_temperature', 'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr'],\n",
    "    window=144\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>air_temperature_mean_lag144</th>\n",
       "      <th>cloud_coverage_mean_lag144</th>\n",
       "      <th>dew_temperature_mean_lag144</th>\n",
       "      <th>precip_depth_1_hr_mean_lag144</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.913685</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.796875</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.703125</td>\n",
       "      <td>0.282715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.908755</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.796875</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.703125</td>\n",
       "      <td>0.282715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.589886</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.796875</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.703125</td>\n",
       "      <td>0.282715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.072639</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.796875</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.703125</td>\n",
       "      <td>0.282715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.666573</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.796875</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.703125</td>\n",
       "      <td>0.282715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  meter  site_id  primary_use  square_feet  air_temperature  \\\n",
       "0            0      0        0            0     8.913685        17.799999   \n",
       "1            1      0        0            0     7.908755        17.799999   \n",
       "2            2      0        0            0     8.589886        17.799999   \n",
       "3            3      0        0            0    10.072639        17.799999   \n",
       "4            4      0        0            0    11.666573        17.799999   \n",
       "\n",
       "   cloud_coverage  dew_temperature  precip_depth_1_hr  hour  day  weekday  \\\n",
       "0             4.0             11.7           0.282609     0    1        6   \n",
       "1             4.0             11.7           0.282609     0    1        6   \n",
       "2             4.0             11.7           0.282609     0    1        6   \n",
       "3             4.0             11.7           0.282609     0    1        6   \n",
       "4             4.0             11.7           0.282609     0    1        6   \n",
       "\n",
       "   month  is_holiday  is_weekend  air_temperature_mean_lag144  \\\n",
       "0      1           0           1                    17.796875   \n",
       "1      1           0           1                    17.796875   \n",
       "2      1           0           1                    17.796875   \n",
       "3      1           0           1                    17.796875   \n",
       "4      1           0           1                    17.796875   \n",
       "\n",
       "   cloud_coverage_mean_lag144  dew_temperature_mean_lag144  \\\n",
       "0                         4.0                    11.703125   \n",
       "1                         4.0                    11.703125   \n",
       "2                         4.0                    11.703125   \n",
       "3                         4.0                    11.703125   \n",
       "4                         4.0                    11.703125   \n",
       "\n",
       "   precip_depth_1_hr_mean_lag144  \n",
       "0                       0.282715  \n",
       "1                       0.282715  \n",
       "2                       0.282715  \n",
       "3                       0.282715  \n",
       "4                       0.282715  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Time: 0:22:10.309010\n"
     ]
    }
   ],
   "source": [
    "prediction_start = dt.now()\n",
    "\n",
    "results = []\n",
    "for model in test_1:\n",
    "    if  results == []:\n",
    "        results = np.expm1(model.predict(test_df_features, num_iteration=model.best_iteration)) / len(test_1)\n",
    "    else:\n",
    "        results += np.expm1(model.predict(test_df_features, num_iteration=model.best_iteration)) / len(test_1)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    \n",
    "print('Prediction Time:', dt.now() - prediction_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "results_df = pd.DataFrame({\"row_id\": row_ids, \"meter_reading\": np.clip(results, 0, a_max=None)})\n",
    "results_df.to_csv(\"submission_02.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>188.160704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>95.259666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17.386316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>251.016449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1028.607648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>27.967194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>87.249422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>634.839855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>721.988880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>253.850937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>42.203180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>14.915753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>943.694994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>319.808981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>150.245514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>105.835692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>52.058010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>281.265399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>567.876131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>214.423846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id  meter_reading\n",
       "0        0     188.160704\n",
       "1        1      95.259666\n",
       "2        2      17.386316\n",
       "3        3     251.016449\n",
       "4        4    1028.607648\n",
       "5        5      27.967194\n",
       "6        6      87.249422\n",
       "7        7     634.839855\n",
       "8        8     721.988880\n",
       "9        9     253.850937\n",
       "10      10      42.203180\n",
       "11      11      14.915753\n",
       "12      12     943.694994\n",
       "13      13     319.808981\n",
       "14      14     150.245514\n",
       "15      15     105.835692\n",
       "16      16      52.058010\n",
       "17      17     281.265399\n",
       "18      18     567.876131\n",
       "19      19     214.423846"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
